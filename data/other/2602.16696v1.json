{
  "id": "http://arxiv.org/abs/2602.16696v1",
  "title": "Parameter-free representations outperform single-cell foundation models on downstream benchmarks",
  "summary": "Single-cell RNA sequencing (scRNA-seq) data exhibit strong and reproducible statistical structure. This has motivated the development of large-scale foundation models, such as TranscriptFormer, that use transformer-based architectures to learn a generative model for gene expression by embedding genes into a latent vector space. These embeddings have been used to obtain state-of-the-art (SOTA) performance on downstream tasks such as cell-type classification, disease-state prediction, and cross-species learning. Here, we ask whether similar performance can be achieved without utilizing computationally intensive deep learning-based representations. Using simple, interpretable pipelines that rely on careful normalization and linear methods, we obtain SOTA or near SOTA performance across multiple benchmarks commonly used to evaluate single-cell foundation models, including outperforming foundation models on out-of-distribution tasks involving novel cell types and organisms absent from the training data. Our findings highlight the need for rigorous benchmarking and suggest that the biology of cell identity can be captured by simple linear representations of single cell gene expression data.",
  "authors": [
    "Huan Souza",
    "Pankaj Mehta"
  ],
  "published": "2026-02-18T18:42:29Z",
  "link": "https://arxiv.org/abs/2602.16696v1",
  "classified_at": "2026-02-23T02:36:49.857859",
  "specialty": "other"
}